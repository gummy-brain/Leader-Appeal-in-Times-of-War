{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1eQeTIKUQ63GlZyhoXzY2_HgUEvobaRnf",
      "authorship_tag": "ABX9TyNjcgb7aMqWu4DXNBgCbLjS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gummy-brain/Leader-Appeal-in-Times-of-War/blob/main/Ukraine_war_Putin_Tweets_dataset_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ukraine Conflict Twitter Dataset (53.87M tweets)\n",
        "\n",
        "2022-10-23"
      ],
      "metadata": {
        "id": "oWmiqlRcKGsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First some preparations to keep our code clean.\n",
        "\n",
        "# imports\n",
        "import os\n",
        "import csv\n",
        "import gzip\n",
        "import zipfile\n",
        "\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from typing import Tuple\n",
        "\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "2z11ROoxKAML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aySAcfRZ4pMz",
        "outputId": "64b1c79b-cac2-45b4-acfe-bed049d3a172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbc_45ZEJXqa"
      },
      "outputs": [],
      "source": [
        "# constants\n",
        "DATA_FOLDER = '/content/gdrive/MyDrive/UkraineTweetsArchive'\n",
        "D_TYPES = {\n",
        "    'userid': 'int64',\n",
        "    'username': 'str',\n",
        "    'acctdesc': 'str',\n",
        "    'location': 'str',\n",
        "    'following': 'int64',\n",
        "    'followers': 'int64',\n",
        "    'totaltweets': 'int64',\n",
        "    'usercreatedts': 'str',\n",
        "    'tweetid': 'int64',\n",
        "    'tweetcreatedts': 'str',\n",
        "    'retweetcount': 'int64',\n",
        "    'text': 'str',\n",
        "    'hashtags': 'str',\n",
        "    'language': 'category',\n",
        "    'coordinates': 'str',\n",
        "    'favorite_count': 'int64',\n",
        "    'extractedts': 'str'\n",
        "}\n",
        "DATE_COLS = ['usercreatedts', 'tweetcreatedts', 'extractedts']\n",
        "\n",
        "# functions\n",
        "def load_file(input: tuple) -> pd.DataFrame:\n",
        "    \"\"\" loading file function for multiprocessing. \"\"\"\n",
        "    path, proces_fnc = input\n",
        "    with gzip.open(DATA_FOLDER + \"/\" + path, 'r') as f:\n",
        "        df = pd.read_csv(f, index_col=0, dtype=D_TYPES, parse_dates=DATE_COLS, encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
        "\n",
        "    return proces_fnc(df)\n",
        "\n",
        "\n",
        "def pre_process(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\" Basic pre-processing function. \"\"\"\n",
        "    if 'is_retweet' in df.columns:\n",
        "        df = df[df['is_retweet'] != True]\n",
        "\n",
        "    df = df[df['language'] == 'en']\n",
        "    df['text'] = df['text'].str.lower()\n",
        "\n",
        "    sample = df.sample(frac=0.01)\n",
        "    pro_russia_tweets = df[df['text'].str.contains(pat = 'istandwithrussia|standwithrussia|istandwithputin|standwithputin|isupportputin|supportputin|isupportrussia|isupportrussia')]\n",
        "    pro_russia_twets = pro_russia_tweets[~pro_russia_tweets['text'].str.contains(pat = \"standwithzelensky|istandwithzelensky|istandwithukraine|standwithukraine|stoprussianow|stoprussia|stopputin|stopputinnow|supportukraine|isupportukraine\")]\n",
        "    return sample, pro_russia_tweets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all data files.\n",
        "files = os.listdir(DATA_FOLDER)\n",
        "\n",
        "# Create inputs for load_file function. (we pass the pre processing logic sepeartely so we can use different preprocessing logic later.)\n",
        "input = [(file, pre_process) for file in files]\n",
        "\n",
        "# Create pool of workers to do file loading and some preprocessing in parallel.\n",
        "with Pool(cpu_count()) as pool:\n",
        "    results = pool.map(load_file, input)\n",
        "\n",
        "en_tweet_dfs, pro_russia_tweets_dfs = zip(*results)\n",
        "# Concat samples into one large sample and save it.\n",
        "sample = pd.concat(en_tweet_dfs)\n",
        "pro_russia_tweets = pd.concat(pro_russia_tweets_dfs)\n",
        "\n",
        "sample.to_pickle('en_tweets_sample.pkl')\n",
        "pro_russia_tweets.to_pickle('pro_russia_tweets.pkl')"
      ],
      "metadata": {
        "id": "7JbOa4H6K-YA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32d5f75c-7c0c-42b9-a503-a8b4843219c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/lib/python3.7/multiprocessing/pool.py:44: DtypeWarning: Columns (18,21,24,25,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  return list(map(*args))\n"
          ]
        }
      ]
    }
  ]
}